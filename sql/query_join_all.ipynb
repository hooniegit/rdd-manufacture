{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/23 14:19:58 WARN Utils: Your hostname, workspace resolves to a loopback address: 127.0.0.1; using 220.118.158.128 instead (on interface eno1)\n",
      "23/12/23 14:19:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/23 14:20:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName(\"spark_join\")\\\n",
    "                  .setMaster(\"spark://workspace:7077\")\n",
    "sparkContext = SparkContext(conf=conf)\n",
    "spark = SparkSession(sparkContext=sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csv_dir = \"file:///home/hooniegit/git/study/rdd-manufacture/data/movielens/ml-latest\"\n",
    "links = spark.read.csv(f\"{csv_dir}/links.csv\", header=True, inferSchema=True)\n",
    "movies = spark.read.csv(f\"{csv_dir}/movies.csv\", header=True, inferSchema=True)\n",
    "ratings = spark.read.csv(f\"{csv_dir}/ratings.csv\", header=True, inferSchema=True)\n",
    "tags = spark.read.csv(f\"{csv_dir}/tags.csv\", header=True, inferSchema=True)\n",
    "\n",
    "links.createOrReplaceTempView(\"links\")\n",
    "movies.createOrReplaceTempView(\"movies\")\n",
    "ratings.createOrReplaceTempView(\"ratings\")\n",
    "tags.createOrReplaceTempView(\"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:====================================================>   (31 + 2) / 33]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+-------+------+----------+\n",
      "|movieId|               title|              genres|userId|movieId|rating| timestamp|\n",
      "+-------+--------------------+--------------------+------+-------+------+----------+\n",
      "| 288983|UNZIPPED: An Auto...|         Documentary|254114| 288983|   3.0|1689834886|\n",
      "| 288977|Skinford: Death S...|      Crime|Thriller|291389| 288977|   3.0|1689815902|\n",
      "| 288975|The Men Who Made ...|         Documentary|154483| 288975|   4.0|1689812351|\n",
      "| 288971|  Ouija Japan (2021)|       Action|Horror| 98408| 288971|   0.5|1689798322|\n",
      "| 288967|State of Siege: T...|        Action|Drama| 47791| 288967|   3.5|1689748357|\n",
      "| 288965|     Камертон (1979)|             Romance|167321| 288965|   2.5|1689747309|\n",
      "| 288959|Letters Of Happin...|      Children|Drama|180878| 288959|   2.0|1689723318|\n",
      "| 288957|Ballet Of Blood (...|              Horror| 11969| 288957|   1.0|1689719936|\n",
      "| 288955|Agata's Friends (...|               Drama|308174| 288955|   2.0|1689707314|\n",
      "| 288953|The Eyes Have It ...|              Comedy|154483| 288953|   1.5|1689651150|\n",
      "| 288951|A Taste of Whale ...|         Documentary|230023| 288951|   3.5|1689713808|\n",
      "| 288949|Eldorado: Everyth...|         Documentary|327439| 288949|   0.5|1689647030|\n",
      "| 288947|The Year I Starte...|Comedy|Drama|Romance|217563| 288947|   0.5|1689618045|\n",
      "| 288945|Mr. Car and the K...|           Adventure| 61020| 288945|   1.0|1689620448|\n",
      "| 288945|Mr. Car and the K...|           Adventure|217563| 288945|   0.5|1689616599|\n",
      "| 288943|  The Mount 2 (2023)|              Horror| 87764| 288943|   1.5|1689606991|\n",
      "| 288941|Mixed Baggage (2023)|Comedy|Drama|Romance| 16020| 288941|   4.5|1689573317|\n",
      "| 288941|Mixed Baggage (2023)|Comedy|Drama|Romance|  7644| 288941|   5.0|1689599382|\n",
      "| 288939|Wedding Season (2...|      Comedy|Romance|  7644| 288939|   5.0|1689599406|\n",
      "| 288939|Wedding Season (2...|      Comedy|Romance| 16020| 288939|   3.5|1689567187|\n",
      "+-------+--------------------+--------------------+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_1 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            movies m\n",
    "        LEFT JOIN\n",
    "            ratings r\n",
    "        ON\n",
    "            m.movieId = r.movieId\n",
    "        ORDER BY\n",
    "            m.movieId DESC  \n",
    "    \"\"\"\n",
    ")\n",
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33832162"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 121:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------+------+------+------+----------+------------------+\n",
      "|movieId|               title|              genres| imdbId|tmdbId|userId|rating| timestamp|               tag|\n",
      "+-------+--------------------+--------------------+-------+------+------+------+----------+------------------+\n",
      "| 111759|Edge of Tomorrow ...|  Action|Sci-Fi|IMAX|1631867|137113|    37|   5.0|1578167954|            action|\n",
      "| 111759|Edge of Tomorrow ...|  Action|Sci-Fi|IMAX|1631867|137113|    37|   5.0|1578167954|            comedy|\n",
      "| 111759|Edge of Tomorrow ...|  Action|Sci-Fi|IMAX|1631867|137113|    37|   5.0|1578167954|            sci-fi|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|       Bill Murray|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|    Cate Blanchett|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|  great soundtrack|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|            quirky|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|visually appealing|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|      Wes Anderson|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|      Willem Dafoe|\n",
      "|  97860|Killing Them Soft...|Crime|Drama|Thriller|1764234| 64689|   137|   4.0|1617154740|    cinematography|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|        Bill Nighy|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|          charming|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|           lovable|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|              love|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|           romance|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|       time travel|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|          touching|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|     unusual story|\n",
      "| 165549|Manchester by the...|               Drama|4034228|334541|   137|   4.5|1603769528|       blue collar|\n",
      "+-------+--------------------+--------------------+-------+------+------+------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_2 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            m.movieId,\n",
    "            m.title,\n",
    "            m.genres,\n",
    "            l.imdbId,\n",
    "            l.tmdbId,\n",
    "            r.userId,\n",
    "            r.rating,\n",
    "            r.timestamp,\n",
    "            t.tag\n",
    "        FROM\n",
    "            movies m\n",
    "        LEFT JOIN\n",
    "            links l\n",
    "        ON\n",
    "            m.movieId = l.movieId\n",
    "        LEFT JOIN\n",
    "            ratings r\n",
    "        ON\n",
    "            m.movieId = r.movieId\n",
    "        INNER JOIN\n",
    "            tags t\n",
    "        ON\n",
    "            r.userId = t.userId\n",
    "            AND\n",
    "            r.movieId = t.movieId\n",
    "    \"\"\"\n",
    ")\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1729292"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- imdbId: integer (nullable = true)\n",
      " |-- tmdbId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 150:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|extracted_chars|\n",
      "+---------------+\n",
      "|             ac|\n",
      "|             co|\n",
      "|             sc|\n",
      "|             Bi|\n",
      "|             Ca|\n",
      "|             gr|\n",
      "|             qu|\n",
      "|             vi|\n",
      "|             We|\n",
      "|             Wi|\n",
      "|             ci|\n",
      "|             Bi|\n",
      "|             ch|\n",
      "|             lo|\n",
      "|             lo|\n",
      "|             ro|\n",
      "|             ti|\n",
      "|             to|\n",
      "|             un|\n",
      "|             bl|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_3 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            SUBSTRING(tag FROM 1 FOR 2) AS extracted_chars\n",
    "        FROM\n",
    "            df\n",
    "    \"\"\"\n",
    ")\n",
    "df_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 174:=====================================================> (33 + 1) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|               title|             genre|\n",
      "+--------------------+------------------+\n",
      "|    Firm, The (1993)|             Drama|\n",
      "|The Duke of Burgu...|             Drama|\n",
      "|         Cube (1997)|            Horror|\n",
      "|Erin Brockovich (...|             Drama|\n",
      "|Irreversible (Irr...|             Crime|\n",
      "|Millennium Actres...|         Animation|\n",
      "|About Schmidt (2002)|            Comedy|\n",
      "|Bill & Ted's Exce...|         Adventure|\n",
      "|     Spectral (2016)|(no genres listed)|\n",
      "|The Accountant (2...|             Crime|\n",
      "|Rosemary's Baby (...|             Drama|\n",
      "|Sixth Sense, The ...|             Drama|\n",
      "|       Saw II (2005)|            Horror|\n",
      "|   Magic Mike (2012)|             Drama|\n",
      "|New World (Shin-s...|          Thriller|\n",
      "|The Lighthouse (2...|             Drama|\n",
      "|A Man Called Ove ...|            Comedy|\n",
      "|    Desperado (1995)|            Action|\n",
      "|      Oddball (2015)|          Children|\n",
      "|Xiu Xiu: The Sent...|             Drama|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_4 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT DISTINCT\n",
    "            title,\n",
    "            SPLIT_PART(genres, '|', 1) AS genre\n",
    "        FROM\n",
    "            df\n",
    "    \"\"\"\n",
    ")\n",
    "df_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 208:===================================================>   (32 + 2) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|      concat_result|\n",
      "+-------------------+\n",
      "| Comedy Documentary|\n",
      "|   Fantasy Thriller|\n",
      "|    Action Children|\n",
      "|Documentary Mystery|\n",
      "|           Musical |\n",
      "|    Animation Crime|\n",
      "|         Film-Noir |\n",
      "|         Action War|\n",
      "|         Adventure |\n",
      "|  Adventure Mystery|\n",
      "|    Fantasy Romance|\n",
      "|   Children Fantasy|\n",
      "|   Adventure Horror|\n",
      "|  Animation Mystery|\n",
      "|    Children Horror|\n",
      "|      Drama Musical|\n",
      "|    Horror Thriller|\n",
      "|       Drama Sci-Fi|\n",
      "|Documentary Fantasy|\n",
      "|      Action Comedy|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_5 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT DISTINCT\n",
    "            CONCAT(m.column1, ' ', m.column2) AS concat_result\n",
    "        FROM \n",
    "            (\n",
    "                SELECT\n",
    "                    SPLIT_PART(genres, \"|\", 1) column1,\n",
    "                    SPLIT_PART(genres, \"|\", 2) column2\n",
    "                FROM\n",
    "                    df\n",
    "            ) m\n",
    "    \"\"\"\n",
    ")\n",
    "df_5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 271:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|               title|              genres|      updated_genres|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|Edge of Tomorrow ...|  Action|Sci-Fi|IMAX| UNKNOWN|Sci-Fi|IMAX|\n",
      "|Edge of Tomorrow ...|  Action|Sci-Fi|IMAX| UNKNOWN|Sci-Fi|IMAX|\n",
      "|Edge of Tomorrow ...|  Action|Sci-Fi|IMAX| UNKNOWN|Sci-Fi|IMAX|\n",
      "|Life Aquatic with...|Adventure|Comedy|...|Adventure|Comedy|...|\n",
      "|Life Aquatic with...|Adventure|Comedy|...|Adventure|Comedy|...|\n",
      "|Life Aquatic with...|Adventure|Comedy|...|Adventure|Comedy|...|\n",
      "|Life Aquatic with...|Adventure|Comedy|...|Adventure|Comedy|...|\n",
      "|Life Aquatic with...|Adventure|Comedy|...|Adventure|Comedy|...|\n",
      "|Life Aquatic with...|Adventure|Comedy|...|Adventure|Comedy|...|\n",
      "|Life Aquatic with...|Adventure|Comedy|...|Adventure|Comedy|...|\n",
      "|Killing Them Soft...|Crime|Drama|Thriller|Crime|Drama|Thriller|\n",
      "|   About Time (2013)|Drama|Fantasy|Rom...|Drama|Fantasy|Rom...|\n",
      "|   About Time (2013)|Drama|Fantasy|Rom...|Drama|Fantasy|Rom...|\n",
      "|   About Time (2013)|Drama|Fantasy|Rom...|Drama|Fantasy|Rom...|\n",
      "|   About Time (2013)|Drama|Fantasy|Rom...|Drama|Fantasy|Rom...|\n",
      "|   About Time (2013)|Drama|Fantasy|Rom...|Drama|Fantasy|Rom...|\n",
      "|   About Time (2013)|Drama|Fantasy|Rom...|Drama|Fantasy|Rom...|\n",
      "|   About Time (2013)|Drama|Fantasy|Rom...|Drama|Fantasy|Rom...|\n",
      "|   About Time (2013)|Drama|Fantasy|Rom...|Drama|Fantasy|Rom...|\n",
      "|Manchester by the...|               Drama|               Drama|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_6 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            title,\n",
    "            genres,\n",
    "            CASE\n",
    "                WHEN genres LIKE '%Action%' THEN REPLACE(genres, 'Action', 'UNKNOWN')\n",
    "                ELSE genres\n",
    "            END updated_genres\n",
    "        FROM df;\n",
    "    \"\"\"\n",
    ")\n",
    "df_6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 283:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|genre_fixed|\n",
      "+--------------------+-----------+\n",
      "|Edge of Tomorrow ...|     Action|\n",
      "|Edge of Tomorrow ...|     Action|\n",
      "|Edge of Tomorrow ...|     Action|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Killing Them Soft...|      Crime|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|Manchester by the...|      Drama|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_7 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            title,\n",
    "            CASE\n",
    "                WHEN genre = \"Romance\" THEN REPLACE(genre, \"Romance\", \"UNKNOWN\")\n",
    "                ELSE genre\n",
    "            END genre_fixed\n",
    "        FROM\n",
    "            (\n",
    "                SELECT\n",
    "                    title,\n",
    "                    SPLIT_PART(genres, \"|\", 1) genre\n",
    "                FROM\n",
    "                    df\n",
    "            ) m\n",
    "    \"\"\"\n",
    ")\n",
    "df_7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 295:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|genre_fixed|\n",
      "+--------------------+-----------+\n",
      "|Edge of Tomorrow ...|     Action|\n",
      "|Edge of Tomorrow ...|     Action|\n",
      "|Edge of Tomorrow ...|     Action|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Life Aquatic with...|  Adventure|\n",
      "|Killing Them Soft...|      Crime|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|   About Time (2013)|      Drama|\n",
      "|Manchester by the...|      Drama|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_8 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            title,\n",
    "            REPLACE(genre, 'Romance', 'UNKNOWN') genre_fixed\n",
    "        FROM (\n",
    "                SELECT\n",
    "                    title,\n",
    "                    SPLIT_PART(genres, '|', 1) AS genre\n",
    "                FROM\n",
    "                    df\n",
    "            ) m\n",
    "    \"\"\"\n",
    ")\n",
    "df_8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 343:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "| timestamp|           datetime|\n",
      "+----------+-------------------+\n",
      "|1578167954|2020-01-05 04:59:14|\n",
      "|1578167954|2020-01-05 04:59:14|\n",
      "|1578167954|2020-01-05 04:59:14|\n",
      "|1529288440|2018-06-18 11:20:40|\n",
      "|1529288440|2018-06-18 11:20:40|\n",
      "|1529288440|2018-06-18 11:20:40|\n",
      "|1529288440|2018-06-18 11:20:40|\n",
      "|1529288440|2018-06-18 11:20:40|\n",
      "|1529288440|2018-06-18 11:20:40|\n",
      "|1529288440|2018-06-18 11:20:40|\n",
      "|1617154740|2021-03-31 10:39:00|\n",
      "|1595825008|2020-07-27 13:43:28|\n",
      "|1595825008|2020-07-27 13:43:28|\n",
      "|1595825008|2020-07-27 13:43:28|\n",
      "|1595825008|2020-07-27 13:43:28|\n",
      "|1595825008|2020-07-27 13:43:28|\n",
      "|1595825008|2020-07-27 13:43:28|\n",
      "|1595825008|2020-07-27 13:43:28|\n",
      "|1595825008|2020-07-27 13:43:28|\n",
      "|1603769528|2020-10-27 12:32:08|\n",
      "+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_9 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            timestamp,\n",
    "            CAST(timestamp AS TIMESTAMP) datetime\n",
    "        FROM\n",
    "            df\n",
    "    \"\"\"\n",
    ")\n",
    "df_9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- datetime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_9.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 391:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----------+----+-----+---+\n",
      "|               title|           datetime|      date|year|month|day|\n",
      "+--------------------+-------------------+----------+----+-----+---+\n",
      "|Edge of Tomorrow ...|2020-01-05 04:59:14|2020-01-05|2020|    1|  5|\n",
      "|Edge of Tomorrow ...|2020-01-05 04:59:14|2020-01-05|2020|    1|  5|\n",
      "|Edge of Tomorrow ...|2020-01-05 04:59:14|2020-01-05|2020|    1|  5|\n",
      "|Life Aquatic with...|2018-06-18 11:20:40|2018-06-18|2018|    6| 18|\n",
      "|Life Aquatic with...|2018-06-18 11:20:40|2018-06-18|2018|    6| 18|\n",
      "|Life Aquatic with...|2018-06-18 11:20:40|2018-06-18|2018|    6| 18|\n",
      "|Life Aquatic with...|2018-06-18 11:20:40|2018-06-18|2018|    6| 18|\n",
      "|Life Aquatic with...|2018-06-18 11:20:40|2018-06-18|2018|    6| 18|\n",
      "|Life Aquatic with...|2018-06-18 11:20:40|2018-06-18|2018|    6| 18|\n",
      "|Life Aquatic with...|2018-06-18 11:20:40|2018-06-18|2018|    6| 18|\n",
      "|Killing Them Soft...|2021-03-31 10:39:00|2021-03-31|2021|    3| 31|\n",
      "|   About Time (2013)|2020-07-27 13:43:28|2020-07-27|2020|    7| 27|\n",
      "|   About Time (2013)|2020-07-27 13:43:28|2020-07-27|2020|    7| 27|\n",
      "|   About Time (2013)|2020-07-27 13:43:28|2020-07-27|2020|    7| 27|\n",
      "|   About Time (2013)|2020-07-27 13:43:28|2020-07-27|2020|    7| 27|\n",
      "|   About Time (2013)|2020-07-27 13:43:28|2020-07-27|2020|    7| 27|\n",
      "|   About Time (2013)|2020-07-27 13:43:28|2020-07-27|2020|    7| 27|\n",
      "|   About Time (2013)|2020-07-27 13:43:28|2020-07-27|2020|    7| 27|\n",
      "|   About Time (2013)|2020-07-27 13:43:28|2020-07-27|2020|    7| 27|\n",
      "|Manchester by the...|2020-10-27 12:32:08|2020-10-27|2020|   10| 27|\n",
      "+--------------------+-------------------+----------+----+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_new = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            title,\n",
    "            FROM_UNIXTIME(timestamp) datetime,\n",
    "            DATE(FROM_UNIXTIME(timestamp)) date,\n",
    "            YEAR(FROM_UNIXTIME(timestamp)) year,\n",
    "            MONTH(FROM_UNIXTIME(timestamp)) month,\n",
    "            DAY(FROM_UNIXTIME(timestamp)) day\n",
    "        FROM\n",
    "            df\n",
    "    \"\"\"\n",
    ")\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- datetime: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 403:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------+------+------+------+----------+------------------+----------+\n",
      "|movieId|               title|              genres| imdbId|tmdbId|userId|rating| timestamp|               tag|new_column|\n",
      "+-------+--------------------+--------------------+-------+------+------+------+----------+------------------+----------+\n",
      "| 111759|Edge of Tomorrow ...|  Action|Sci-Fi|IMAX|1631867|137113|    37|   5.0|1578167954|            action|      NULL|\n",
      "| 111759|Edge of Tomorrow ...|  Action|Sci-Fi|IMAX|1631867|137113|    37|   5.0|1578167954|            comedy|      NULL|\n",
      "| 111759|Edge of Tomorrow ...|  Action|Sci-Fi|IMAX|1631867|137113|    37|   5.0|1578167954|            sci-fi|      NULL|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|       Bill Murray|      NULL|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|    Cate Blanchett|      NULL|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|  great soundtrack|      NULL|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|            quirky|      NULL|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|visually appealing|      NULL|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|      Wes Anderson|      NULL|\n",
      "|  30810|Life Aquatic with...|Adventure|Comedy|...| 362270|   421|   137|   4.0|1529288440|      Willem Dafoe|      NULL|\n",
      "|  97860|Killing Them Soft...|Crime|Drama|Thriller|1764234| 64689|   137|   4.0|1617154740|    cinematography|      NULL|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|        Bill Nighy|      NULL|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|          charming|      NULL|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|           lovable|      NULL|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|              love|      NULL|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|           romance|      NULL|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|       time travel|      NULL|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|          touching|      NULL|\n",
      "| 104374|   About Time (2013)|Drama|Fantasy|Rom...|2194499|122906|   137|   4.5|1595825008|     unusual story|      NULL|\n",
      "| 165549|Manchester by the...|               Drama|4034228|334541|   137|   4.5|1603769528|       blue collar|      NULL|\n",
      "+-------+--------------------+--------------------+-------+------+------+------+----------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_10 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT \n",
    "            *,\n",
    "            NULL new_column\n",
    "        FROM\n",
    "            df\n",
    "    \"\"\"\n",
    ")\n",
    "df_10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 552:=====================================================> (33 + 1) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+\n",
      "|userId|movieId|avg(rating)|\n",
      "+------+-------+-----------+\n",
      "|  4776|   4487|        2.0|\n",
      "|  9138| 105504|        3.0|\n",
      "| 15869|  58490|        3.5|\n",
      "| 23936|   1979|        4.0|\n",
      "| 33191| 103228|        2.0|\n",
      "| 48392|   1198|        5.0|\n",
      "| 54964|   4448|        3.5|\n",
      "| 54976|    318|        4.0|\n",
      "| 58115| 157645|        3.0|\n",
      "| 64903|    260|        5.0|\n",
      "| 65508|   1148|        5.0|\n",
      "| 67371|  42723|        4.0|\n",
      "| 68714|   2918|        2.5|\n",
      "| 74305|   6870|        4.0|\n",
      "| 75656|  40614|        3.0|\n",
      "| 97841|   6016|        5.0|\n",
      "|102081|   2772|        3.5|\n",
      "|106986|   2321|        5.0|\n",
      "|109540|    322|        3.5|\n",
      "|110878|  93991|        4.0|\n",
      "+------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_11 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            userId,\n",
    "            movieId,\n",
    "            AVG(rating)\n",
    "        FROM\n",
    "            df\n",
    "        GROUP BY\n",
    "            CUBE(userId, movieId)\n",
    "    \"\"\"\n",
    ")\n",
    "df_11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 566:(18 + 12) / 30][Stage 568:(10 + 11) / 21][Stage 569:>  (0 + 1) / 1]1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+\n",
      "|userId|movieId|avg(rating)|\n",
      "+------+-------+-----------+\n",
      "+------+-------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_11_2 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            userId,\n",
    "            movieId,\n",
    "            AVG(rating)\n",
    "        FROM\n",
    "            df\n",
    "        WHERE\n",
    "            movieId IS NULL\n",
    "        GROUP BY\n",
    "            CUBE(userId, movieId)\n",
    "    \"\"\"\n",
    ")\n",
    "df_11_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 598:=====================================================> (33 + 1) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------------+\n",
      "|userId|movieId|       avg(rating)|\n",
      "+------+-------+------------------+\n",
      "|  2612|   NULL| 3.745798319327731|\n",
      "|  7570|   NULL|3.8206140350877194|\n",
      "|  9138|   NULL|3.6265380778184237|\n",
      "| 22760|   NULL|              4.76|\n",
      "| 24124|   NULL|3.7107438016528924|\n",
      "| 40914|   NULL|3.9656549520766773|\n",
      "| 53440|   NULL|3.5621783876500857|\n",
      "| 64075|   NULL|              4.75|\n",
      "|142955|   NULL|4.3052631578947365|\n",
      "|153618|   NULL|3.5315315315315314|\n",
      "|154895|   NULL|               3.5|\n",
      "|158762|   NULL| 4.642857142857143|\n",
      "|173607|   NULL|3.7916666666666665|\n",
      "|186899|   NULL|               5.0|\n",
      "|190361|   NULL|              3.75|\n",
      "|191380|   NULL|3.4761904761904763|\n",
      "|210820|   NULL|             3.875|\n",
      "|219386|   NULL|3.9004065040650406|\n",
      "|232216|   NULL|            4.5125|\n",
      "|247014|   NULL|            4.0625|\n",
      "+------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_11_3 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            userId,\n",
    "            movieId,\n",
    "            AVG(rating)\n",
    "        FROM\n",
    "            df\n",
    "        GROUP BY\n",
    "            CUBE(userId, movieId)\n",
    "        HAVING\n",
    "            movieId IS NULL\n",
    "    \"\"\"\n",
    ")\n",
    "df_11_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 632:===================================================>   (32 + 2) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------------+\n",
      "|userId|movieId|       avg(rating)|\n",
      "+------+-------+------------------+\n",
      "|  NULL|  45950| 2.369688385269122|\n",
      "|  NULL| 149334| 3.959051724137931|\n",
      "|  NULL|  87232| 3.065356004250797|\n",
      "|  NULL|   3101| 3.378640776699029|\n",
      "|  NULL| 217465|3.5713101160862353|\n",
      "|  NULL|  47518|3.7976190476190474|\n",
      "|  NULL|  70336|1.3766114180478821|\n",
      "|  NULL|  77328| 2.783333333333333|\n",
      "|  NULL|    741| 4.334033613445378|\n",
      "|  NULL| 103042| 3.388246628131021|\n",
      "|  NULL|    342|3.8897637795275593|\n",
      "|  NULL|   3696|3.1066666666666665|\n",
      "|  NULL| 177867| 3.607142857142857|\n",
      "|  NULL|   7790|              3.75|\n",
      "|  NULL|   2353|3.9385245901639343|\n",
      "|  NULL|   2183| 3.686991869918699|\n",
      "|  NULL|    616|3.6370967741935485|\n",
      "|  NULL|  71322|3.3666666666666667|\n",
      "|  NULL| 216671|               3.0|\n",
      "|  NULL| 131714|               3.3|\n",
      "+------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_11_4 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            (\n",
    "                SELECT\n",
    "                    userId,\n",
    "                    movieId,\n",
    "                    AVG(rating)\n",
    "                FROM\n",
    "                    df\n",
    "                GROUP BY\n",
    "                    CUBE(userId, movieId)\n",
    "            )\n",
    "        WHERE\n",
    "            userId IS NULL\n",
    "    \"\"\"\n",
    ")\n",
    "df_11_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 615:==============================================>        (29 + 5) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------------+\n",
      "|userId|movieId|       avg(rating)|\n",
      "+------+-------+------------------+\n",
      "|  2612|   NULL| 3.745798319327731|\n",
      "|  7570|   NULL|3.8206140350877194|\n",
      "|  9138|   NULL|3.6265380778184237|\n",
      "| 14960|   NULL|               4.5|\n",
      "| 15830|   NULL|              4.75|\n",
      "| 24124|   NULL|3.7107438016528924|\n",
      "| 40914|   NULL|3.9656549520766773|\n",
      "| 53440|   NULL|3.5621783876500857|\n",
      "|102058|   NULL|            4.8125|\n",
      "|117314|   NULL|3.6914893617021276|\n",
      "|124416|   NULL|            3.6875|\n",
      "|142221|   NULL|               5.0|\n",
      "|153618|   NULL|3.5315315315315314|\n",
      "|158762|   NULL| 4.642857142857143|\n",
      "|168788|   NULL|               4.1|\n",
      "|172736|   NULL| 4.815384615384615|\n",
      "|173640|   NULL|               4.5|\n",
      "|175141|   NULL| 3.923076923076923|\n",
      "|195858|   NULL|  4.87719298245614|\n",
      "|210820|   NULL|             3.875|\n",
      "+------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_12 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            userId,\n",
    "            movieId,\n",
    "            AVG(rating)\n",
    "        FROM\n",
    "            df\n",
    "        GROUP BY\n",
    "            ROLLUP(userId, movieId)\n",
    "        HAVING\n",
    "            movieId IS NULL\n",
    "    \"\"\"\n",
    ")\n",
    "df_12.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 642:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+\n",
      "|userId|movieId|avg(rating)|\n",
      "+------+-------+-----------+\n",
      "|114125|     31|        3.0|\n",
      "|114151|     31|        4.0|\n",
      "|114172|     31|        3.0|\n",
      "|114282|     31|        3.0|\n",
      "|114283|     31|        3.5|\n",
      "|114299|     31|        4.0|\n",
      "|114301|     31|        4.0|\n",
      "|114352|     31|        3.5|\n",
      "|114398|     31|        2.0|\n",
      "|114406|     31|        3.0|\n",
      "|114411|     31|        3.0|\n",
      "|114449|     31|        5.0|\n",
      "|114451|     31|        3.0|\n",
      "|114493|     31|        0.5|\n",
      "|114517|     31|        3.0|\n",
      "|114550|     31|        3.0|\n",
      "|114684|     31|        3.0|\n",
      "|114688|     31|        3.0|\n",
      "|114694|     31|        5.0|\n",
      "|114812|     31|        4.0|\n",
      "+------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# OUTER JOIN 사용 시, AVG(r.rating) 값이 없을 수도 있으므로 userId 기준으로 movieId를 GroupBy를 해 주어야 함\n",
    "df_13 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            r.userId,\n",
    "            m.movieId,\n",
    "            AVG(r.rating)\n",
    "        FROM\n",
    "            movies m\n",
    "        LEFT JOIN\n",
    "            ratings r\n",
    "        ON\n",
    "            m.movieId = r.movieId\n",
    "        GROUP BY\n",
    "            r.userId, m.movieId\n",
    "    \"\"\"\n",
    ")\n",
    "df_13.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 652:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+\n",
      "|userId|movieId|avg(rating)|\n",
      "+------+-------+-----------+\n",
      "| 23231|     31|        4.0|\n",
      "| 23250|     31|        4.0|\n",
      "| 23302|     31|        5.0|\n",
      "| 23323|     31|        3.5|\n",
      "| 23329|     31|        3.0|\n",
      "| 23331|     31|        3.0|\n",
      "| 23366|     31|        4.0|\n",
      "| 23404|     31|        3.0|\n",
      "| 23480|     31|        3.0|\n",
      "| 23511|     31|        4.0|\n",
      "| 23535|     31|        4.0|\n",
      "| 23537|     31|        4.5|\n",
      "| 23543|     31|        3.0|\n",
      "| 23544|     31|        4.0|\n",
      "| 23561|     31|        3.0|\n",
      "| 23567|     31|        3.5|\n",
      "| 23571|     31|        3.0|\n",
      "| 23595|     31|        5.0|\n",
      "| 23699|     31|        4.0|\n",
      "| 23768|     31|        4.5|\n",
      "+------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# OUTER JOIN 사용 시, AVG(r.rating) 값이 없을 수도 있으므로 GroupBy를 해 주어야 함\n",
    "df_13_2 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            r.userId,\n",
    "            m.movieId,\n",
    "            r.rating\n",
    "        FROM\n",
    "            movies m\n",
    "        LEFT JOIN\n",
    "            ratings r\n",
    "        ON\n",
    "            m.movieId = r.movieId\n",
    "    \"\"\"\n",
    ")\n",
    "df_13.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
